{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip show pyspark"
      ],
      "metadata": {
        "collapsed": true,
        "id": "73goMx0XK8FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1PdYchPlRt8K",
        "outputId": "11839a1f-ed6f-4244-9995-0c8e093f3909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [1 InRelease 14.2 kB/129\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Connected to cloud.r-pr\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \r                                                                               \rGet:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://cli.github.com/packages stable/main amd64 Packages [343 B]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,143 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,828 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,458 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,863 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,188 kB]\n",
            "Fetched 26.5 MB in 7s (4,020 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless session-migration x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libxt-doc openjdk-8-demo openjdk-8-source visualvm libnss-mdns\n",
            "  fonts-nanum fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libgail-common libgail18 libgtk2.0-0\n",
            "  libgtk2.0-bin libgtk2.0-common librsvg2-common libxcomposite1 libxt-dev\n",
            "  libxtst6 libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless session-migration x11-utils\n",
            "0 upgraded, 26 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 50.3 MB of archives.\n",
            "After this operation, 170 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [30.8 MB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre amd64 8u462-ga~us1-0ubuntu2~22.04.2 [75.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [8,849 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk amd64 8u462-ga~us1-0ubuntu2~22.04.2 [4,105 kB]\n",
            "Fetched 50.3 MB in 2s (27.0 MB/s)\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "(Reading database ... 121703 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../01-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../02-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../03-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../04-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../05-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../06-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../07-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../08-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../09-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../10-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../12-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../13-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../14-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../15-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../16-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../17-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../18-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../19-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../20-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../21-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../22-openjdk-8-jre-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../23-openjdk-8-jre_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../24-openjdk-8-jdk-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../25-openjdk-8-jdk_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service â†’ /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf spark-3.2.0-bin-hadoop3.2\n",
        "!rm -rf spark-3.0.3-bin-hadoop3.2\n",
        "!rm -f spark-3.*.tgz"
      ],
      "metadata": {
        "id": "YWENS1o_h8BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1ERS1griCqL",
        "outputId": "112a1297-05a6-49ec-fd26-6cc763152845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"17.0.16\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install Dependencies\n",
        "# Install JDK 8 (still necessary for the JVM)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Install the correct PySpark version (3.5.1) and a utility library\n",
        "# The 'pyspark' package contains all necessary Java binaries, simplifying setup.\n",
        "!pip install -q pyspark==3.5.1\n",
        "\n",
        "# 2. Set Java Home\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Set JAVA_HOME, which is often the final piece needed for the JVM\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# 3. Create the SparkSession\n",
        "# PySpark will now use its internal libraries and findspark is not strictly needed.\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ColabSparkAuto\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.memory\", \"6g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"Spark initialized successfully! Spark Version:\", spark.version)"
      ],
      "metadata": {
        "id": "_rUWSFp1iHhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4956a9b8-362e-48d8-dfe1-39585f189817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---\n",
            "Spark initialized successfully! Spark Version: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set environment variables for Java\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n"
      ],
      "metadata": {
        "id": "c3DDViTSSauO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the mock data (list of tuples)\n",
        "data = [\n",
        "    ('Alice', 1, 'New York', 75000),\n",
        "    ('Bob', 2, 'London', 90000),\n",
        "    ('Charlie', 3, 'Paris', 62000),\n",
        "    ('David', 4, 'New York', 88000),\n",
        "    ('Eve', 5, 'London', 105000)\n",
        "]\n",
        "\n",
        "# Define the schema (column names)\n",
        "columns = [\"Name\", \"ID\", \"City\", \"Salary\"]\n",
        "\n",
        "# Create the DataFrame\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "## ðŸ’¡ Key Inspection Concepts\n",
        "\n",
        "# .show(): Displays the top rows of the DataFrame\n",
        "print(\"\\n--- Displaying the DataFrame (.show()) ---\")\n",
        "df.show()\n",
        "\n",
        "# .printSchema(): Shows the column names and data types (schema)\n",
        "print(\"\\n--- Displaying the Schema (.printSchema()) ---\")\n",
        "df.printSchema()\n",
        "\n",
        "# .count(): Returns the number of rows (an Action)\n",
        "print(\"\\n--- Row Count (.count()) ---\")\n",
        "print(\"Total Rows:\", df.count())\n",
        "\n",
        "# .describe(): Computes statistics for numerical columns\n",
        "print(\"\\n--- Descriptive Statistics (.describe()) ---\")\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdvtZWP0ytmy",
        "outputId": "fd70043f-65d6-41e2-8c35-f009d20c365d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Displaying the DataFrame (.show()) ---\n",
            "+-------+---+--------+------+\n",
            "|   Name| ID|    City|Salary|\n",
            "+-------+---+--------+------+\n",
            "|  Alice|  1|New York| 75000|\n",
            "|    Bob|  2|  London| 90000|\n",
            "|Charlie|  3|   Paris| 62000|\n",
            "|  David|  4|New York| 88000|\n",
            "|    Eve|  5|  London|105000|\n",
            "+-------+---+--------+------+\n",
            "\n",
            "\n",
            "--- Displaying the Schema (.printSchema()) ---\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- ID: long (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Salary: long (nullable = true)\n",
            "\n",
            "\n",
            "--- Row Count (.count()) ---\n",
            "Total Rows: 5\n",
            "\n",
            "--- Descriptive Statistics (.describe()) ---\n",
            "+-------+-----+------------------+------+------------------+\n",
            "|summary| Name|                ID|  City|            Salary|\n",
            "+-------+-----+------------------+------+------------------+\n",
            "|  count|    5|                 5|     5|                 5|\n",
            "|   mean| NULL|               3.0|  NULL|           84000.0|\n",
            "| stddev| NULL|1.5811388300841898|  NULL|16263.455967290593|\n",
            "|    min|Alice|                 1|London|             62000|\n",
            "|    max|  Eve|                 5| Paris|            105000|\n",
            "+-------+-----+------------------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lit\n",
        "\n",
        "df_filtered = df.filter(\n",
        "    (col(\"City\") == \"New York\") & (col(\"Salary\") > 8000)\n",
        ")\n",
        "df_filtered.show()\n",
        "\n",
        "df_with_add_col = df.withColumn(\"Income Tax\", col(\"Salary\") * 12/100)\n",
        "df_with_add_col.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G301vHBIzlLj",
        "outputId": "d28bc1d3-e575-4774-c47f-cc3bf3dc2cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+--------+------+\n",
            "| Name| ID|    City|Salary|\n",
            "+-----+---+--------+------+\n",
            "|Alice|  1|New York| 75000|\n",
            "|David|  4|New York| 88000|\n",
            "+-----+---+--------+------+\n",
            "\n",
            "+-------+---+--------+------+----------+\n",
            "|   Name| ID|    City|Salary|Income Tax|\n",
            "+-------+---+--------+------+----------+\n",
            "|  Alice|  1|New York| 75000|    9000.0|\n",
            "|    Bob|  2|  London| 90000|   10800.0|\n",
            "|Charlie|  3|   Paris| 62000|    7440.0|\n",
            "|  David|  4|New York| 88000|   10560.0|\n",
            "|    Eve|  5|  London|105000|   12600.0|\n",
            "+-------+---+--------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, sum, avg, count\n",
        "\n",
        "# Mock review data (Product ID, Rating, Reviewer Location)\n",
        "review_data = [\n",
        "    (101, 5, 'USA'),\n",
        "    (102, 4, 'Canada'),\n",
        "    (101, 4, 'USA'),\n",
        "    (103, 5, 'Mexico'),\n",
        "    (102, 1, 'Canada'),\n",
        "    (101, 5, 'USA'),\n",
        "    (103, 3, 'Mexico'),\n",
        "    (104, 5, 'USA'),\n",
        "    (104, 2, 'USA')\n",
        "]\n",
        "review_columns = [\"product_id\", \"rating\", \"location\"]\n",
        "\n",
        "review_df = spark.createDataFrame(review_data, review_columns)\n",
        "print(\"\\n--- Original Review Data ---\")\n",
        "review_df.show()\n",
        "review_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2BzFNx6hld",
        "outputId": "f0a7f8f6-b0f8-4a95-f7da-968c1e16cffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Original Review Data ---\n",
            "+----------+------+--------+\n",
            "|product_id|rating|location|\n",
            "+----------+------+--------+\n",
            "|       101|     5|     USA|\n",
            "|       102|     4|  Canada|\n",
            "|       101|     4|     USA|\n",
            "|       103|     5|  Mexico|\n",
            "|       102|     1|  Canada|\n",
            "|       101|     5|     USA|\n",
            "|       103|     3|  Mexico|\n",
            "|       104|     5|     USA|\n",
            "|       104|     2|     USA|\n",
            "+----------+------+--------+\n",
            "\n",
            "root\n",
            " |-- product_id: long (nullable = true)\n",
            " |-- rating: long (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_rating_review = review_df.groupBy(\"product_id\").agg(\n",
        "    avg(\"rating\").alias(\"Avg rating\"),\n",
        "    count(\"rating\").alias(\"Total Reviews\")\n",
        ").sort(col(\"product_id\"))\n",
        "\n",
        "print(\"Product Summary -\")\n",
        "df_rating_review.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk8Ci7Vu75_o",
        "outputId": "3aa7ad77-911a-40d5-fab3-bd0e00a87b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Summary -\n",
            "+----------+-----------------+-------------+\n",
            "|product_id|       Avg rating|Total Reviews|\n",
            "+----------+-----------------+-------------+\n",
            "|       101|4.666666666666667|            3|\n",
            "|       102|              2.5|            2|\n",
            "|       103|              4.0|            2|\n",
            "|       104|              3.5|            2|\n",
            "+----------+-----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mock product details (Product ID, Name, Category)\n",
        "details_data = [\n",
        "    (101, 'Laptop', 'Electronics'),\n",
        "    (102, 'T-Shirt', 'Apparel'),\n",
        "    (103, 'Coffee Maker', 'Home Goods'),\n",
        "    (104, 'Book', 'Media'),\n",
        "    (105, 'Headphones', 'Electronics') # This product has no reviews (yet)\n",
        "]\n",
        "details_columns = [\"product_id\", \"product_name\", \"category\"]\n",
        "\n",
        "details_df = spark.createDataFrame(details_data, details_columns)\n",
        "print(\"\\n--- Product Details Data ---\")\n",
        "details_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cRcZT0FDPJ7",
        "outputId": "9a3bd930-f009-4bdc-e468-a3d414997a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Product Details Data ---\n",
            "+----------+------------+-----------+\n",
            "|product_id|product_name|   category|\n",
            "+----------+------------+-----------+\n",
            "|       101|      Laptop|Electronics|\n",
            "|       102|     T-Shirt|    Apparel|\n",
            "|       103|Coffee Maker| Home Goods|\n",
            "|       104|        Book|      Media|\n",
            "|       105|  Headphones|Electronics|\n",
            "+----------+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products_quality = df_rating_review.join(\n",
        "    details_df, on=\"product_id\", how=\"left\"\n",
        ").select(col(\"product_id\"), col(\"product_name\"), col(\"category\"), col(\"Avg rating\"), col(\"Total Reviews\")\n",
        ").sort(col(\"product_name\"))\n",
        "\n",
        "print(\"\\n--- Products Quality ---\")\n",
        "products_quality.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCAfouVLMUI9",
        "outputId": "69738c5b-e47e-4c43-9b07-3e322f26d610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Products Quality ---\n",
            "+----------+------------+-----------+-----------------+-------------+\n",
            "|product_id|product_name|   category|       Avg rating|Total Reviews|\n",
            "+----------+------------+-----------+-----------------+-------------+\n",
            "|       104|        Book|      Media|              3.5|            2|\n",
            "|       103|Coffee Maker| Home Goods|              4.0|            2|\n",
            "|       101|      Laptop|Electronics|4.666666666666667|            3|\n",
            "|       102|     T-Shirt|    Apparel|              2.5|            2|\n",
            "+----------+------------+-----------+-----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, sum, avg, count, current_timestamp\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
        "from datetime import date\n",
        "\n",
        "# (Assuming 'spark' is already initialized from previous steps)\n",
        "\n",
        "sales_data = [\n",
        "    (\"A\", 100, date(2025, 1, 1)),\n",
        "    (\"B\", 150, date(2025, 1, 1)),\n",
        "    (\"A\", 200, date(2025, 1, 2)),\n",
        "    (\"A\", 50, date(2025, 1, 2)), # Important: Two sales on the same day for Team A\n",
        "    (\"B\", 300, date(2025, 1, 2)),\n",
        "    (\"C\", 400, date(2025, 1, 3)),\n",
        "    (\"A\", 250, date(2025, 1, 3)),\n",
        "    (\"C\", 100, date(2025, 1, 4)),\n",
        "    (\"B\", 500, date(2025, 1, 4)),\n",
        "    (\"A\", 50, date(2025, 1, 4)),\n",
        "]\n",
        "\n",
        "sales_columns = [\"team\", \"sales_amount\", \"sale_date\"]\n",
        "\n",
        "sales_df = spark.createDataFrame(sales_data, sales_columns)\n",
        "\n",
        "print(\"\\n--- Original Sales Data (Sorted by Date) ---\")\n",
        "sales_df.sort(\"team\", \"sale_date\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTc-iN8qddBE",
        "outputId": "8604a172-c66e-4b80-e84b-8ba0201e4b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Original Sales Data (Sorted by Date) ---\n",
            "+----+------------+----------+\n",
            "|team|sales_amount| sale_date|\n",
            "+----+------------+----------+\n",
            "|   A|         100|2025-01-01|\n",
            "|   A|         200|2025-01-02|\n",
            "|   A|          50|2025-01-02|\n",
            "|   A|         250|2025-01-03|\n",
            "|   A|          50|2025-01-04|\n",
            "|   B|         150|2025-01-01|\n",
            "|   B|         300|2025-01-02|\n",
            "|   B|         500|2025-01-04|\n",
            "|   C|         400|2025-01-03|\n",
            "|   C|         100|2025-01-04|\n",
            "+----+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "window_spec_running_total = Window.partitionBy(\"Team\").orderBy(\"sale_date\").rowsBetween(Window.unboundedPreceding, Window.currentRow)"
      ],
      "metadata": {
        "id": "dvOKLUZph2ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running_total_df = sales_df.withColumn(\n",
        "    \"cumulative_sales\", sum(col(\"sales_amount\")).over(window_spec_running_total)\n",
        ").sort(\"team\", \"sale_date\")\n",
        "\n",
        "print(\"Running Total :\")\n",
        "running_total_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAlu7Tfco_Y3",
        "outputId": "9559f219-7b03-4509-fb69-1898d5343eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Total :\n",
            "+----+------------+----------+----------------+\n",
            "|team|sales_amount| sale_date|cumulative_sales|\n",
            "+----+------------+----------+----------------+\n",
            "|   A|         100|2025-01-01|             100|\n",
            "|   A|         200|2025-01-02|             300|\n",
            "|   A|          50|2025-01-02|             350|\n",
            "|   A|         250|2025-01-03|             600|\n",
            "|   A|          50|2025-01-04|             650|\n",
            "|   B|         150|2025-01-01|             150|\n",
            "|   B|         300|2025-01-02|             450|\n",
            "|   B|         500|2025-01-04|             950|\n",
            "|   C|         400|2025-01-03|             400|\n",
            "|   C|         100|2025-01-04|             500|\n",
            "+----+------------+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, rand\n",
        "from pyspark.storagelevel import StorageLevel\n",
        "\n",
        "import time\n",
        "\n",
        "# mock dataframe\n",
        "large_sales_df = spark.range(1000000).withColumn(\"sales_value\", rand()*1000)\n",
        "# large_sales_df.show(5)\n",
        "\n",
        "# add a column that need complex transformation\n",
        "large_sales_df = large_sales_df.withColumn(\n",
        "    \"is_high_value\",\n",
        "    (col(\"sales_value\") > 800)\n",
        ")\n",
        "\n",
        "print(f\"Data frame is ready with {large_sales_df.count()} rows.\" )\n",
        "large_sales_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aiGf8p2GU6W",
        "outputId": "7658b914-453a-4a2e-82e8-994ae41670ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data frame is ready with 1000000 rows.\n",
            "+---+------------------+-------------+\n",
            "| id|       sales_value|is_high_value|\n",
            "+---+------------------+-------------+\n",
            "|  0| 946.9472217076882|         true|\n",
            "|  1| 949.3896769184495|         true|\n",
            "|  2| 728.7301605284208|        false|\n",
            "|  3|138.52727335666847|        false|\n",
            "|  4| 889.7328632486704|         true|\n",
            "+---+------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# without chaching computed data\n",
        "large_sales_df.unpersist()\n",
        "\n",
        "start_time = time.time()\n",
        "large_sales_df.groupBy(\"is_high_value\").count().show(1) # Action 1\n",
        "time_no_cache_1 = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "large_sales_df.agg({\"sales_value\" : \"avg\"}).show(1) # Action 2\n",
        "time_no_cache_2 = time.time() - start_time\n",
        "\n",
        "print(f\"time without caching Action 1: {time_no_cache_1:.4f}\")\n",
        "print(f\"time without caching Action 2: {time_no_cache_2:.4f}\") # lineage reexecuted\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUyJBFxgInze",
        "outputId": "e1474a48-d47e-4400-cd5d-fbe194cfe664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+\n",
            "|is_high_value| count|\n",
            "+-------------+------+\n",
            "|         true|199566|\n",
            "+-------------+------+\n",
            "only showing top 1 row\n",
            "\n",
            "+-----------------+\n",
            "| avg(sales_value)|\n",
            "+-----------------+\n",
            "|499.7963839873064|\n",
            "+-----------------+\n",
            "\n",
            "time without caching Action 1: 0.6116\n",
            "time without caching Action 2: 0.3625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with caching computed data\n",
        "# caching the dataframe in memory\n",
        "large_sales_df.persist(StorageLevel.MEMORY_ONLY) # set the cache true\n",
        "\n",
        "start_time = time.time()\n",
        "large_sales_df.groupBy()\n",
        "\n",
        "large_sales_df.groupBy(\"is_high_value\").count().show(1) # Action 1\n",
        "time_with_cache_1 = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "large_sales_df.agg({\"sales_value\": \"avg\"}).show(1)     # Second Action (Reads from Cache)\n",
        "time_with_cache_2 = time.time() - start_time\n",
        "\n",
        "print(f\"time without caching Action 1: {time_with_cache_1:.4f}\")\n",
        "print(f\"time without caching Action 2: {time_with_cache_2:.4f}\") # lineage reexecuted\n",
        "large_sales_df.unpersist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfkV2s4eVYN_",
        "outputId": "506f3ab4-85a6-485e-a833-b1798a50006f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------+\n",
            "|is_high_value| count|\n",
            "+-------------+------+\n",
            "|         true|199566|\n",
            "+-------------+------+\n",
            "only showing top 1 row\n",
            "\n",
            "+-----------------+\n",
            "| avg(sales_value)|\n",
            "+-----------------+\n",
            "|499.7963839873064|\n",
            "+-----------------+\n",
            "\n",
            "time without caching Action 1: 2.1210\n",
            "time without caching Action 2: 0.5441\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: bigint, sales_value: double, is_high_value: boolean]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "category_data = [\n",
        "    (1, \"Electronics\"),\n",
        "    (2, \"Apparel\"),\n",
        "    (3, \"Home Goods\"),\n",
        "    (4, \"Media\"),\n",
        "    (5, \"Books\")\n",
        "]\n",
        "category_cols = [\"category_id\", \"category_name\"]\n",
        "small_dim_df = spark.createDataFrame(category_data, category_cols)\n",
        "\n",
        "# Large DF\n",
        "large_transaction_df = spark.range(1000000) \\\n",
        "    .withColumnRenamed(\"id\",\"transaction_id\") \\\n",
        "    .withColumn(\"category_id\", (col(\"transaction_id\") % 5) + 1) # Add IDs 1 to 5\n",
        "\n",
        "print(f\"Small DF Count: {small_dim_df.count()}, Large DF Count: {large_transaction_df.count()}\")\n",
        "\n",
        "start_time = time.time()\n",
        "united_small_large_df = large_transaction_df.join(\n",
        "    broadcast(small_dim_df),\n",
        "    on = \"category_id\",\n",
        "    how = \"inner\"\n",
        ")\n",
        "united_small_large_df.show(10)\n",
        "time_broadcast_join = time.time() - start_time\n",
        "\n",
        "print(f\"time with broadcast join: {time_broadcast_join}\")"
      ],
      "metadata": {
        "id": "WS_qQh-CBEvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487cac70-de5e-4337-8aae-0d2baefb56a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small DF Count: 5, Large DF Count: 1000000\n",
            "+-----------+--------------+-------------+\n",
            "|category_id|transaction_id|category_name|\n",
            "+-----------+--------------+-------------+\n",
            "|          1|             0|  Electronics|\n",
            "|          2|             1|      Apparel|\n",
            "|          3|             2|   Home Goods|\n",
            "|          4|             3|        Media|\n",
            "|          5|             4|        Books|\n",
            "|          1|             5|  Electronics|\n",
            "|          2|             6|      Apparel|\n",
            "|          3|             7|   Home Goods|\n",
            "|          4|             8|        Media|\n",
            "|          5|             9|        Books|\n",
            "+-----------+--------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "time with broadcast join: 0.5385096073150635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicate and Pushdown\n",
        "output_path = \"/content/tmp/patitioned_data\"\n",
        "\n",
        "!rm -rf {output_path}\n",
        "\n",
        "united_small_large_df.write \\\n",
        ".mode(\"overwrite\") \\\n",
        ".partitionBy(\"category_name\") \\\n",
        ".parquet(output_path)\n",
        "\n",
        "# Verify the file structure on disk\n",
        "!ls -l {output_path}\n",
        "!ls -l {output_path}/category_name=Electronics/\n"
      ],
      "metadata": {
        "id": "8AWxH8rrFkUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae22d10-f3bc-49c2-9524-524fbefba2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 20\n",
            "drwxr-xr-x 2 root root 4096 Nov 17 13:45 'category_name=Apparel'\n",
            "drwxr-xr-x 2 root root 4096 Nov 17 13:45 'category_name=Books'\n",
            "drwxr-xr-x 2 root root 4096 Nov 17 13:45 'category_name=Electronics'\n",
            "drwxr-xr-x 2 root root 4096 Nov 17 13:45 'category_name=Home Goods'\n",
            "drwxr-xr-x 2 root root 4096 Nov 17 13:45 'category_name=Media'\n",
            "-rw-r--r-- 1 root root    0 Nov 17 13:45  _SUCCESS\n",
            "total 792\n",
            "-rw-r--r-- 1 root root 403534 Nov 17 13:45 part-00000-780ef021-7972-4596-92cb-00b86b455c21.c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 403570 Nov 17 13:45 part-00001-780ef021-7972-4596-92cb-00b86b455c21.c000.snappy.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query 1: Only interested in books transactions\n",
        "\n",
        "spark.read.parquet(output_path).filter(col(\"category_name\") == \"Books\").show(10)\n",
        "spark.read.parquet(output_path).filter(col(\"category_name\") == \"Books\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AG7p1TFKdro",
        "outputId": "21d35609-1dea-4b73-815c-ac238599b0a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+-------------+\n",
            "|category_id|transaction_id|category_name|\n",
            "+-----------+--------------+-------------+\n",
            "|          5|        500004|        Books|\n",
            "|          5|        500009|        Books|\n",
            "|          5|        500014|        Books|\n",
            "|          5|        500019|        Books|\n",
            "|          5|        500024|        Books|\n",
            "|          5|        500029|        Books|\n",
            "|          5|        500034|        Books|\n",
            "|          5|        500039|        Books|\n",
            "|          5|        500044|        Books|\n",
            "|          5|        500049|        Books|\n",
            "+-----------+--------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}